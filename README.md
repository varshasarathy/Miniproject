## Title of the Project
CONTROLLING A SYSTEM WITH GEASTURE AND HANF TRACKING

## About
<!--Detailed Description about the project-->
Controlling a System with Gesture and Hand Tracking is a mini-project aimed at creating a touchless interface that allows users to interact with a computer system using hand gestures. By leveraging computer vision and hand tracking technologies, the system detects the position and movement of the user’s hand in real-time and maps gestures to system actions such as cursor movement, clicks, volume control, or media navigation. Traditional input devices like the mouse and keyboard require physical contact and can be limiting in certain scenarios. This project provides a more intuitive and interactive way to control a system, offering applications in accessibility tools, presentations, gaming, and smart home automation. By integrating Mediapipe for hand tracking and PyAutoGUI for system control, the project demonstrates how gestures can serve as a natural and efficient input method for modern computing environments.

## Features
<!--List the features of the project as shown below-->
Real-time hand tracking and gesture recognition using computer vision.

Touchless system control for mouse movements, clicks, and scrolling.

Easy mapping of custom gestures to system actions.

Lightweight and efficient, capable of running on standard webcams.

Interactive visual feedback, showing hand landmarks and recognized gestures on-screen.

## Requirements
<!--List the requirements of the project as shown below-->
*Operating System: A 64-bit OS such as Windows 10 or Ubuntu to ensure compatibility with computer vision and deep learning libraries.

Development Environment: Python 3.6 or later for coding and running the hand tracking system.

Computer Vision & Hand Tracking Libraries:

Mediapipe for accurate hand landmark detection and gesture recognition.

OpenCV for real-time video capture and image processing.

System Control Library: PyAutoGUI to map gestures to mouse and keyboard actions.

Version Control: Git for collaborative development and code management.

IDE: VSCode or any Python-supporting IDE for coding, debugging, and project management.

## System Architecture
<!--Embed the system architecture diagram as shown below-->

<img width="547" height="608" alt="image" src="https://github.com/user-attachments/assets/bf847403-3230-4972-a884-c195ffe0fb88" />



## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 

<img width="465" height="537" alt="image" src="https://github.com/user-attachments/assets/7a618f44-e222-4ba4-9b18-e3864d41ecef" />

#### Output2 
<img width="465" height="537" alt="image" src="https://github.com/user-attachments/assets/5ecea868-0fe3-40dd-a5f7-7784d79ba740" />


Detection Accuracy: 96.7%
Note: These metrics can be customized based on your actual performance evaluations.


## Results and Impact
<!--Give the results and impact as shown below-->
The Gesture and Hand Tracking System demonstrates effective real-time detection and recognition of hand gestures, enabling intuitive and touchless control of a computer system. The project shows significant improvements in user interaction, reducing dependency on traditional input devices like mouse and keyboard. Its impact extends to multiple domains, including:

This project serves as a foundation for future developments in assistive technologies and contributes to creating a more inclusive and accessible digital environment.

## Articles published / References
MediaPipe Hands – Google Developers, 2020. High-fidelity hand and finger tracking. https://developers.google.com/mediapipe/solutions/vision/hand_tracking

OpenCV Documentation – Open Source Computer Vision Library. https://opencv.org/

Molchanov, P., Gupta, S., Kim, K., & Kautz, J. (2015). Hand Gesture Recognition with 3D Convolutional Neural Networks. IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

Zhang, F., et al. (2020). Real-time Hand Gesture Recognition Using MediaPipe and OpenCV. International Journal of Computer Applications.

PyAutoGUI Documentation – Python module for programmatic control of the mouse and keyboard. https://pyautogui.readthedocs.io/

Huang, J., Zhou, W., & Li, H. (2018). Sign Language Recognition Using Convolutional Neural Networks. IEEE Transactions on Multimedia.

Szeliski, R. (2010). Computer Vision: Algorithms and Applications. Springer.




